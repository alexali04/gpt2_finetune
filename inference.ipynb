{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMdZa49RBMuR32xvilFeacT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexali04/gpt2_finetune/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import torch.nn.functional as F\n",
        "import csv"
      ],
      "metadata": {
        "id": "XNOIfppTf-KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "summaries = pd.read_csv('/content/drive/MyDrive/summaries.csv')\n",
        "reviews = pd.read_csv('/content/drive/MyDrive/reviews.csv', engine='python', error_bad_lines=False)"
      ],
      "metadata": {
        "id": "yJTBLeSqf9tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_relevant = summaries[['uid', 'synopsis']].rename(columns = {'uid':'summary_uid', 'synopsis':'text'})\n",
        "reviews_relevant = reviews[['uid', 'synopsis']].rename(columns = {'uid': 'anime_uid'})\n",
        "reviews_relevant = reviews[['uid', 'text']]\n",
        "reviews_relevant['text'] = reviews_relevant['text'].str.replace(\"more pics\", \"\", case=False, regex=True)\n",
        "reviews_relevant = reviews_relevant.sample(n = 18000) # number subject to change\n",
        "animes_relevant = summaries_relevant.sample(n = 18000)\n",
        "df = pd.concat([summaries_relevant, reviews_relevant], ignore_index=True)"
      ],
      "metadata": {
        "id": "5vn-ip-HgZ8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['text'].notnull()]\n",
        "df = df[df['uid'].notnull()]\n",
        "df = df[df['text'].str.strip() != \"\"] ## filter out empty values"
      ],
      "metadata": {
        "id": "qHQcqEjegaZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = df.sample(n = 5)\n",
        "df = df.loc[~df.index.isin(test_set.index)]\n",
        "print(df.shape)\n",
        "\n",
        "# reset indices\n",
        "test_set = test_set.reset_index()\n",
        "df = df.reset_index()\n",
        "\n",
        "# for the test set keep last 20 words in a new col and remove from original col\n",
        "test_set['true_end'] = test_set['text'].str.split().str[-20:].apply(' '.join)\n",
        "test_set['text'] = test_set['text'].str.split().str[:-20].apply(' '.join)\n",
        "#test_set.to_csv(\"/content/test.csv\")"
      ],
      "metadata": {
        "id": "iS7WS_Oagdd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "7hdm3C1EdGww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/model_large.pth\", map_location=torch.device('cpu')))\n",
        "## IF GPU: model.load_state_dict(torch.load(\"/content/drive/MyDrive/model_small.pth\"))\n",
        "## probably load large after training"
      ],
      "metadata": {
        "id": "aGMN5-EBgg7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_prompt(gpt_model, prompt, n_out_tokens):\n",
        "\n",
        "  model_inputs = tokenizer(prompt, return_tensors = 'pt')\n",
        "\n",
        "  excess_tokens = model_inputs[\"input_ids\"].shape[1] + n_out_tokens - 984 ## 984 = 1024 - 40\n",
        "  if excess_tokens > 0:\n",
        "    model_inputs[\"input_ids\"] = model_inputs[\"input_ids\"][:, excess_tokens:] # remove from beginning\n",
        "\n",
        "    if \"attention_mask\" in model_inputs:\n",
        "      model_inputs[\"attention_mask\"] = model_inputs[\"attention_mask\"][:, excess_tokens:]\n",
        "\n",
        "  len_input = model_inputs[\"input_ids\"].shape[1]\n",
        "  print(len_input)\n",
        "\n",
        "  output_tokens = gpt_model.generate(\n",
        "      **model_inputs,\n",
        "      max_new_tokens = n_out_tokens + 40,\n",
        "      min_new_tokens = n_out_tokens,\n",
        "      do_sample = True,\n",
        "      top_p = 0.92,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      num_beams = 1\n",
        "  )\n",
        "\n",
        "  return tokenizer.decode(output_tokens[0][len_input:], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "MHPL5PEDFdfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(test_data, gpt_model):\n",
        "  generated_text = []\n",
        "  for i in range(len(test_data)):\n",
        "    output_text = complete_prompt(gpt_model, test_data['text'][i], 40) # 40 - 80 tokens :)\n",
        "    generated_text.append(output_text)\n",
        "    print(i)\n",
        "\n",
        "  return generated_text"
      ],
      "metadata": {
        "id": "vCQSRcNMY_ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_regular = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "iBaT3vjzZXfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_text = generate_text(test_set, model)\n",
        "regular_text = generate_text(test_set, model_regular)"
      ],
      "metadata": {
        "id": "IJ38Y1hKgkMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "0pPp3P83S2cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(generated_text):\n",
        "  my_generations = []\n",
        "\n",
        "  for i in range(len(generated_text)):\n",
        "    a = test_set['text'][i].split()[-30:]\n",
        "    b = ' '.join(a)\n",
        "    c = generated_text[i]\n",
        "    if b:\n",
        "      my_generations.append(c.split(b)[-1])\n",
        "    else:\n",
        "      my_generations.append(c)\n",
        "\n",
        "\n",
        "  final = []\n",
        "\n",
        "  for i in range(len(test_set)):\n",
        "    to_remove = my_generations[i].split('.')[-1]\n",
        "    final.append(my_generations[i].replace(to_remove,''))\n",
        "\n",
        "  return final\n",
        "\n",
        "clean_finetuned_text = clean_text(fine_tuned_text) # clean text\n",
        "clean_regular_text = clean_text(regular_text)"
      ],
      "metadata": {
        "id": "2LXepH67Zax5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f\"Prompt: {test_set['text'][i]}\\n\") ## 40 onwards\n",
        "  print(f\"True Ending: {test_set['true_end'][i]}\\n\")\n",
        "  print(f\"continuation from fine tuned model: {clean_finetuned_text[i]}\\n\")\n",
        "  print(f\"continuation from GPT2: {clean_regular_text[i]}\\n\")\n",
        "  print(\"\\n\\n\")\n",
        "\n",
        "## for holistic evaluation"
      ],
      "metadata": {
        "id": "PUkwUEgugm1_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}